{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e3d2f2-8cbe-4ede-9bfe-d69d09de43e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5a0518-9b51-429d-8c94-f81d2e20db6b",
   "metadata": {},
   "source": [
    "# 1. Is `nn.Linear(...)` a pytorch model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57ce45-fda4-407c-b04b-d0382275adc2",
   "metadata": {},
   "source": [
    "# 2. Which methods pytorch models inherited from nn.Module does have?\n",
    "\n",
    "- `__init__(self)`: the constructor method that defines the parts that make up the model, even if these parts are other models themselves.\n",
    "- `forward(self, x)`: the forward pass, that is, the method that takes an input x (features) and outputs the corresponding model's predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c308ae31-6f87-4415-a8ab-dbf189f8f003",
   "metadata": {},
   "source": [
    "# 3. How can we inspect the values of params of a initialized pytorch model?\n",
    "\n",
    "- `state_dict()`\n",
    "\n",
    "`state_dict` can traverse the models inside models, and return the params in a recursively way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95975da0-7179-4bcc-844b-d253c692309c",
   "metadata": {},
   "source": [
    "# 4. What represent `requires_grad=True` on tensors by pytorch?\n",
    "\n",
    "Means that every tensor with the param `requires_grad=True` will be learned during training, during the autograd process. This is set to True by default for every parameter of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7fc42-5ec1-4ab5-889f-8393ae49b5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cdae25a-3230-4f60-aa89-4077e0e92e02",
   "metadata": {},
   "source": [
    "# 5. Give-me an example of the pattern of higher-oder functions, applied on pytorch framework\n",
    "\n",
    "All loss functions implemented on pytorch framework are higher-order functions.\n",
    "\n",
    "```py\n",
    "loss_fn = nn.MSELoss()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1310a1e-f6f3-42e2-8f92-07ec344e4a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ec22460-9062-48bb-b96e-d948fc366923",
   "metadata": {},
   "source": [
    "# 6. Describe intuitively how we should update params values of a model, in order to decrease the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad87f8f0-9196-418e-8dc8-965cdf8c5e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b25c69b-0c04-4c8d-9d7c-83cba6d94518",
   "metadata": {},
   "source": [
    "# 7. Do you know what is a gradient?\n",
    "\n",
    "*The gradient means how much the loss changes if we change one parameters of our model by a little bit*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d962cd4-1118-4dcc-a343-62702f8ecf9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a777a65b-e68f-4f11-a9fb-1f0d97ed3344",
   "metadata": {},
   "source": [
    "# 8. What is the most important step during optimization?\n",
    "\n",
    "Use the method `.zero_grad()` to clean the gradient values. This avoid a very common problem during the training of deep learning models, the gradient accumulation. There is some situations that accumulate the gradient is very useful, but not always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90be1b2a-7608-4482-bed5-4dba687a5393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ce77231-ffe7-455a-8d6b-c08a40db83d4",
   "metadata": {},
   "source": [
    "# 9. Why optimizers does have `state_dict()` methods too, like models?\n",
    "\n",
    "There is some internal variables that some optimizers need to track. Like momentum, or other feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ddcf1e-1e4b-4c93-afed-eebd80598882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e006a952-ff84-43f3-b247-82aab39639ad",
   "metadata": {},
   "source": [
    "# 10. Why is importante to us to put the model on training mode right before the forward pass?\n",
    "\n",
    "By calling `model.train()` we're setting the model to training mode, making it behave differentlt than the alternative - evaluation mode - in some specific cases. During the use of **Dropout** for example, setting a model to training mode allows dropout to randomly drop some weights form the computation.\n",
    "\n",
    "When we use the validation data during the training loop of a model, we'll put the model in evaluation mode to not update the weights and still evaluate the results. Because of that, always remember to put your model in training mode on the start of the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf668fa-66a5-4e50-bb96-b8c343704159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "747f669d-46ba-43c7-bb6a-a214e6053ad3",
   "metadata": {},
   "source": [
    "# 11. Create a simple model and a training loop for that model (you can use any data you want). The training loop should also have a validation loss tracking, to compare the training and validation loss curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a769a2-23ff-4e48-98b7-a88221ab400b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef248e61-df6f-43b3-9b78-52655b8f7a54",
   "metadata": {},
   "source": [
    "# 12. Why should we use Modulelist instead of ordinary lists to represent a list of layers on our Deep Learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9810a22-5b1d-4020-8de1-8badd93ff4ab",
   "metadata": {},
   "source": [
    "`ModuleList` is a special type of list, one that allows PyTorch to recursively look for learnable params of layers and models inside its contents. As it turns out, if the class attribute of your custom model is a regular Python list, any layers or models inside it will be ignored by pytorch during training. By explicitly making a ModuleList out of a regular python list we ensure that its params are also accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e298e79-59c4-4dd8-82eb-375faea54e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b665ae1-52e9-4ef5-a62c-efb7a847aad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41802cb5-8fca-4326-82e5-d71ef22598e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc053390-817f-4570-9879-982c402e9cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f1f08-aca5-466e-a578-847a01751111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
