{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c7a65b2-0678-4d94-9bb2-37e11b6cf9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611ed48-ade6-49f6-9c38-6c0fad3096da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c68b8433-409e-424b-b4bc-8bc8e9a364f3",
   "metadata": {},
   "source": [
    "# 1. What is a TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe7f8ff-7c64-4336-a873-ce18d325718e",
   "metadata": {},
   "source": [
    "Tensor datasets are one of the most basic types of datasets you'll find in pytorch. They simply wrap a couple of tensors containing your data, so you can convenientlty load your data in mini-batches at will for training your model.\n",
    "\n",
    "The result from a TensorDataset seams a list of tuples:\n",
    "- (features, target)\n",
    "\n",
    "Where in each idx, we have a batch of features and targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06c7b0d-b184-4492-8ce9-d8a030456263",
   "metadata": {},
   "source": [
    "# 2. How does mini-batches can be used to save memory during training large models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a1eea0-ad12-4920-bf3e-7a83d28fa51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39e71e1c-6867-4dce-aa32-f97686cf4889",
   "metadata": {},
   "source": [
    "# 3. Explain the following params of a DataLoader class\n",
    "\n",
    "- **dataset**: the underlying dataset it will be drawing samples from\n",
    "- **batch_size**: the number of data points in each batch returned by it\n",
    "- **drop_last**: drop the last mini-batch if there aren't batch_size data points in it\n",
    "- **shuffle**: shuffle (or not) the data\n",
    "- **pin_memory**: pins data to a location in memory, thus allowing data to be moved faster between CPU and GPU.\n",
    "- **num_workers**: number of parallel process that should be used to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47938da1-d54e-4d78-aeed-59de55fbecbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7c87f7e-d02a-41b3-abc1-b3e629b42a4b",
   "metadata": {},
   "source": [
    "# 4. Represent how we can set the method `manual_seed` to a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bab4dac-b644-42a8-aa78-ff7dee2fdd72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d5b51-10f0-44bd-8b61-43b5b54e454b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "250e05c8-9dc7-49f7-b696-a588381a4a63",
   "metadata": {},
   "source": [
    "# 5. Give-me one use case of th sampler method used by dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d4b1e-feaf-451d-b96c-792297cd1a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d69fe995-cea6-4e28-8c9a-578c67a969d8",
   "metadata": {},
   "source": [
    "# 6. Create a dataset and a dataloader from a tabular data, you can use mpg dataset from the course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd0339-2e63-4435-b531-9d616130bd20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a75a16cf-b712-405a-8784-f25614a1c311",
   "metadata": {},
   "source": [
    "# 7. Explain the following params of ImageFolder generic dataset class:\n",
    "\n",
    "- transform:\n",
    "- target_transform:\n",
    "- loader:\n",
    "- is_valid_file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e1577-9aed-45e2-9e0c-e54423261eda",
   "metadata": {},
   "source": [
    "Transform tells the dataset which transformations should be applied to each image.\n",
    "\n",
    "Target transform makes sense for task like segmentation, because this will indicate that our target has a specific format, like an image.\n",
    "\n",
    "Loader is a function that loads an image from a given path, in case you're using weird or atypical formats that cannot be handled by PIL.\n",
    "\n",
    "is_valid_file is a function that checks if a file is corrupted or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1088d0f-e67f-4f92-b765-67204dda170a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b326b3-eeb8-40cc-9cc8-4fe66829261e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64a70b9-6326-48b2-aa30-da89301b9374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ff7d3e-79d6-4189-9410-ef5174007591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f6308-fa60-4300-8319-899ebf754566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
