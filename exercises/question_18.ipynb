{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbe36f2f-df97-422c-b98b-6106b378cf0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46acb756-8270-46ad-8c7a-74a3432ff1ba",
   "metadata": {},
   "source": [
    "# Question 18\n",
    "\n",
    "Create a python script that do the following: \n",
    "- load the Auto MPG Dataset: csv file\n",
    "- split in train test and validation clean those missing data standardize the numerical features apply OrdicalEncoder on those discret features \n",
    "- use nn.Embeddings on just one discret features create a Dataset pytorch class\n",
    "- create a DataLoader pytorch class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6bdaa7-8722-41f3-a592-9791b14c5b47",
   "metadata": {},
   "source": [
    "# Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "65f8eaa3-b95d-4f06-bc55-95b5c7033028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import polars.selectors as cs\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class DataPrep:\n",
    "    def __init__(self):\n",
    "        self.data = pl.read_csv(\"../data/auto_mpg.csv\")\n",
    "        self.X_train = ...\n",
    "        self.y_train = ...\n",
    "        self.X_test = ...\n",
    "        self.y_test = ...\n",
    "        self.X_val = ...\n",
    "        self.y_val = ...\n",
    "        self.ct = ...\n",
    "        self.unique_classes_cyl = ...\n",
    "\n",
    "    def cleaning_data(self) -> None:\n",
    "        self.data = self.data.drop_nulls()\n",
    "\n",
    "    def shuffling_data(self) -> None:\n",
    "        self.data = self.data.sample(fraction=1, shuffle=True, seed=42)\n",
    "\n",
    "    def split_data(self) -> None:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            self.data.drop(\"mpg\"),\n",
    "            self.data.select(\"mpg\"),\n",
    "            test_size=0.2,\n",
    "            random_state=42,\n",
    "        )\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            test_size=0.2,\n",
    "            random_state=42,\n",
    "        )\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "\n",
    "    def encoder(self) -> None:\n",
    "        ct = ColumnTransformer(\n",
    "            [\n",
    "                (\"std_scaler\", StandardScaler(), [\"disp\", \"hp\", \"weight\", \"acc\"]),\n",
    "                (\"ordinal_scaler\", OrdinalEncoder(), [\"cyl\", \"origin\", \"year\"]),\n",
    "            ]\n",
    "        )\n",
    "        self.ct = ct\n",
    "\n",
    "    def fit_transform(self) -> None:\n",
    "        self.X_train = self.ct.fit_transform(self.X_train.to_pandas())\n",
    "        self.X_test = self.ct.transform(self.X_test.to_pandas())\n",
    "        self.X_val = self.ct.transform(self.X_val.to_pandas())\n",
    "        self.new_features = self.ct.get_feature_names_out()\n",
    "\n",
    "        self.X_train = pl.from_numpy(self.X_train)\n",
    "        self.X_train.columns = self.new_features\n",
    "\n",
    "        self.X_test = pl.from_numpy(self.X_test)\n",
    "        self.X_test.columns = self.new_features\n",
    "\n",
    "        self.X_val = pl.from_numpy(self.X_val)\n",
    "        self.X_val.columns = self.new_features\n",
    "\n",
    "        self.unique_classes_cyl = (\n",
    "            self.X_train.select(\"ordinal_scaler__cyl\")\n",
    "            .unique(\"ordinal_scaler__cyl\")\n",
    "            .shape\n",
    "        )\n",
    "\n",
    "    def using_embedding(self) -> None:\n",
    "        embedding_cyl = nn.Embedding(self.unique_classes_cyl[0], 50)\n",
    "\n",
    "        dfs = [self.X_train, self.X_test, self.X_val]\n",
    "        new_dfs = []\n",
    "\n",
    "        for df in dfs:\n",
    "            cyl_to_embed = df.select(\"ordinal_scaler__cyl\").to_numpy()\n",
    "\n",
    "            cyl_embeded = embedding_cyl(torch.LongTensor(cyl_to_embed))\n",
    "\n",
    "            cyl_embedded_tabular = pl.from_numpy(\n",
    "                cyl_embeded.view((-1, 50)).detach().numpy()\n",
    "            )\n",
    "\n",
    "            data = df.drop(\n",
    "                [\n",
    "                    \"ordinal_scaler__cyl\",\n",
    "                    \"ordinal_scaler__origin\",\n",
    "                    \"ordinal_scaler__year\",\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            data = pl.concat(\n",
    "                [\n",
    "                    data,\n",
    "                    cyl_embedded_tabular,\n",
    "                ],\n",
    "                how=\"horizontal\",\n",
    "            )\n",
    "            new_dfs.append(data)\n",
    "\n",
    "        return new_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "247a4497-1bb2-4cc4-867b-fd6327d0891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep = DataPrep()\n",
    "data_prep.cleaning_data()\n",
    "data_prep.shuffling_data()\n",
    "data_prep.split_data()\n",
    "data_prep.encoder()\n",
    "data_prep.fit_transform()\n",
    "X_train, X_test, X_val = data_prep.using_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "862fe46c-dad3-48d4-92d0-a2336284750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X.to_numpy()[idx]\n",
    "        y = self.y.to_numpy()[idx]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "46cfb654-4593-4127-a01f-504c5eefab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MPGDataset(X_train, data_prep.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6d7398b8-d3d8-45c0-a0d1-00d575fea8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9079, -0.6607, -0.9064, -0.5411,  0.3979,  2.1349,  0.0736,  0.3205,\n",
      "         -0.7000, -0.0707,  1.3242,  1.5165,  0.7971,  2.1962, -0.2196,  1.3388,\n",
      "         -0.6371, -0.2119,  0.6129,  0.0561,  0.8354,  0.8953, -0.3982, -1.8467,\n",
      "         -0.7590, -0.0091,  0.0426, -0.0468, -0.1222,  0.2128,  0.2577,  1.1217,\n",
      "         -0.6829,  1.4282, -0.2626, -0.8961,  1.7603,  2.3195,  0.3237,  0.4234,\n",
      "          1.1591,  0.0160, -0.5305,  0.6294, -0.6996,  0.4748,  1.3023,  0.0254,\n",
      "         -0.7422,  0.5812, -0.8319,  1.5225, -0.3287,  0.2177],\n",
      "        [-0.9751, -0.7382, -1.0040, -0.0459,  0.3979,  2.1349,  0.0736,  0.3205,\n",
      "         -0.7000, -0.0707,  1.3242,  1.5165,  0.7971,  2.1962, -0.2196,  1.3388,\n",
      "         -0.6371, -0.2119,  0.6129,  0.0561,  0.8354,  0.8953, -0.3982, -1.8467,\n",
      "         -0.7590, -0.0091,  0.0426, -0.0468, -0.1222,  0.2128,  0.2577,  1.1217,\n",
      "         -0.6829,  1.4282, -0.2626, -0.8961,  1.7603,  2.3195,  0.3237,  0.4234,\n",
      "          1.1591,  0.0160, -0.5305,  0.6294, -0.6996,  0.4748,  1.3023,  0.0254,\n",
      "         -0.7422,  0.5812, -0.8319,  1.5225, -0.3287,  0.2177],\n",
      "        [ 0.3869, -0.3506,  0.1590,  0.6971,  1.6262, -0.1350, -0.6787,  1.7017,\n",
      "          1.2471,  0.1663,  1.8796, -0.5896, -0.6825, -0.9421, -0.1536,  0.6350,\n",
      "          2.5412,  0.8529, -1.5671, -1.1032,  0.9346, -0.1161, -0.4627,  1.5928,\n",
      "          1.2275,  0.2458,  0.2646, -0.8053,  1.2248, -0.5025,  1.9942, -0.5006,\n",
      "         -0.5349,  0.2482,  0.5229,  1.3836, -0.0584,  0.0852,  1.4000,  0.8928,\n",
      "          0.4806,  1.0457, -0.0519,  0.5225, -0.5839, -0.6338,  1.1757, -0.3825,\n",
      "         -1.0112,  1.3522,  0.2407,  1.3795,  2.2801, -0.6594],\n",
      "        [ 1.5188,  1.9749,  1.7005, -1.2487, -1.2755, -0.3942,  0.1868,  0.3671,\n",
      "          0.5500,  0.5785,  0.1449, -0.7380, -0.0036, -0.7083, -0.1344, -0.5448,\n",
      "          0.3313, -0.1867, -1.3375,  2.0719,  0.9352,  0.2346, -0.8936,  0.6803,\n",
      "         -1.0167,  0.1268, -0.6400,  1.4199, -1.0881,  0.3645, -0.3832, -0.7324,\n",
      "          1.4488,  1.2372, -0.8023, -0.1097, -0.3743,  0.1323, -1.7662,  1.7515,\n",
      "          1.0016,  1.2140, -0.4950, -0.1815, -1.0433,  1.6253,  0.1081, -0.0239,\n",
      "          0.5583,  0.0145, -0.1034,  0.6071,  0.6603,  1.4003],\n",
      "        [-0.4955, -0.8157, -0.4600, -0.7180,  0.3979,  2.1349,  0.0736,  0.3205,\n",
      "         -0.7000, -0.0707,  1.3242,  1.5165,  0.7971,  2.1962, -0.2196,  1.3388,\n",
      "         -0.6371, -0.2119,  0.6129,  0.0561,  0.8354,  0.8953, -0.3982, -1.8467,\n",
      "         -0.7590, -0.0091,  0.0426, -0.0468, -0.1222,  0.2128,  0.2577,  1.1217,\n",
      "         -0.6829,  1.4282, -0.2626, -0.8961,  1.7603,  2.3195,  0.3237,  0.4234,\n",
      "          1.1591,  0.0160, -0.5305,  0.6294, -0.6996,  0.4748,  1.3023,  0.0254,\n",
      "         -0.7422,  0.5812, -0.8319,  1.5225, -0.3287,  0.2177]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[30.5000],\n",
      "        [24.0000],\n",
      "        [22.5000],\n",
      "        [16.5000],\n",
      "        [26.5000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=5)\n",
    "\n",
    "for X, y in train_dataloader:\n",
    "    print(X)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b8ae4a-7183-421b-9257-eb90783cfa7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a842d-b581-47cc-bc3a-8842e5595249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b88e4d-d91d-42e4-9883-172b37a50440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
